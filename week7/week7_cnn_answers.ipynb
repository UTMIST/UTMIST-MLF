{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/miniconda3/lib/python3.9/site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in /opt/miniconda3/lib/python3.9/site-packages (3.7.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/miniconda3/lib/python3.9/site-packages (1.4.2)\n",
      "Collecting datasets\n",
      "  Downloading datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/miniconda3/lib/python3.9/site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/miniconda3/lib/python3.9/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/miniconda3/lib/python3.9/site-packages (from matplotlib) (4.39.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/miniconda3/lib/python3.9/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/lib/python3.9/site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/miniconda3/lib/python3.9/site-packages (from matplotlib) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/miniconda3/lib/python3.9/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/miniconda3/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /opt/miniconda3/lib/python3.9/site-packages (from matplotlib) (5.12.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/miniconda3/lib/python3.9/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/miniconda3/lib/python3.9/site-packages (from scikit-learn) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/miniconda3/lib/python3.9/site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: filelock in /Users/roberge/.local/lib/python3.9/site-packages (from datasets) (3.14.0)\n",
      "Collecting pyarrow>=21.0.0 (from datasets)\n",
      "  Downloading pyarrow-21.0.0-cp39-cp39-macosx_12_0_arm64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.4.1,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /opt/miniconda3/lib/python3.9/site-packages (from datasets) (1.4.3)\n",
      "Collecting requests>=2.32.2 (from datasets)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: httpx<1.0.0 in /opt/miniconda3/lib/python3.9/site-packages (from datasets) (0.27.0)\n",
      "Collecting tqdm>=4.66.3 (from datasets)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.6.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.19 (from datasets)\n",
      "  Downloading multiprocess-0.70.18-py39-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /Users/roberge/.local/lib/python3.9/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2024.5.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /opt/miniconda3/lib/python3.9/site-packages (from datasets) (0.29.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/miniconda3/lib/python3.9/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/miniconda3/lib/python3.9/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.10.10)\n",
      "Requirement already satisfied: anyio in /opt/miniconda3/lib/python3.9/site-packages (from httpx<1.0.0->datasets) (4.3.0)\n",
      "Requirement already satisfied: certifi in /opt/miniconda3/lib/python3.9/site-packages (from httpx<1.0.0->datasets) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/miniconda3/lib/python3.9/site-packages (from httpx<1.0.0->datasets) (1.0.5)\n",
      "Requirement already satisfied: idna in /opt/miniconda3/lib/python3.9/site-packages (from httpx<1.0.0->datasets) (3.3)\n",
      "Requirement already satisfied: sniffio in /opt/miniconda3/lib/python3.9/site-packages (from httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/miniconda3/lib/python3.9/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.14.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/roberge/.local/lib/python3.9/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/miniconda3/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.15.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/miniconda3/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/miniconda3/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/lib/python3.9/site-packages (from pandas->datasets) (2022.2.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/miniconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/miniconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/miniconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/miniconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/miniconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /opt/miniconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.16.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/miniconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (4.0.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/miniconda3/lib/python3.9/site-packages (from anyio->httpx<1.0.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/miniconda3/lib/python3.9/site-packages (from yarl<2.0,>=1.12.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.2.0)\n",
      "Downloading datasets-4.4.1-py3-none-any.whl (511 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.6/511.6 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.7/119.7 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.18-py39-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.5/133.5 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-21.0.0-cp39-cp39-macosx_12_0_arm64.whl (31.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.2/31.2 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.6.0-cp39-cp39-macosx_11_0_arm64.whl (30 kB)\n",
      "Installing collected packages: xxhash, tqdm, requests, pyarrow, dill, multiprocess, datasets\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.64.0\n",
      "    Uninstalling tqdm-4.64.0:\n",
      "      Successfully uninstalled tqdm-4.64.0\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pyppeteer 2.0.0 requires urllib3<2.0.0,>=1.25.8, but you have urllib3 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-4.4.1 dill-0.4.0 multiprocess-0.70.18 pyarrow-21.0.0 requests-2.32.5 tqdm-4.67.1 xxhash-3.6.0\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "# Run this cell first if you don't have these packages installed\n",
    "!pip install numpy matplotlib scikit-learn datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bd2187",
   "metadata": {},
   "source": [
    "# Week 7 — Convolutional Neural Networks (Image Classification)\n",
    "\n",
    "**Setup Instructions:**\n",
    "1. Run the cell above to install required packages (if not already installed)\n",
    "2. **Important:** If you get import errors after installing packages, restart the Jupyter kernel:\n",
    "   - Go to `Kernel` → `Restart Kernel` in the menu\n",
    "   - Or use the restart button in the toolbar\n",
    "3. Then re-run the import cell below\n",
    "\n",
    "**Objectives**\n",
    "\n",
    "- Load and visualize the CIFAR-10 dataset from HuggingFace.\n",
    "- Build a PCA + Logistic Regression baseline classifier; compute evaluation metrics (e.g., accuracy).\n",
    "- Implement a simple CNN classifier that barely beats or fails to beat the baseline.\n",
    "- Build a deeper CNN model that achieves better performance.\n",
    "- Train a CNN model on data‑augmented images and visualize augmentations.\n",
    "- Explore an advanced CNN feature (e.g., global average pooling) and observe its impact.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "450f2098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import (\n",
    "    show_result,\n",
    "    load_cifar10_dataset,\n",
    "    pca_logistic_baseline,\n",
    "    test_exercise_7_pca,\n",
    "    test_exercise_7_simple_cnn,\n",
    "    test_exercise_7_proper_cnn,\n",
    "    test_exercise_7_data_aug_cnn,\n",
    "    test_exercise_7_advanced_cnn,\n",
    "    accuracy\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3b55ea",
   "metadata": {},
   "source": [
    "## 1. CIFAR-10 Image Dataset\n",
    "\n",
    "In this exercise, we'll use the CIFAR-10 dataset, a well-known benchmark dataset for image classification. CIFAR-10 contains 60,000 32×32 color images in 10 classes (airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck), with 6,000 images per class.\n",
    "\n",
    "We'll load the dataset from HuggingFace and convert it to grayscale to simplify training and focus on the CNN architecture rather than computational complexity.\n",
    "\n",
    "**Task:** Use the `load_cifar10_dataset` function from `utils.py` to load a subset of CIFAR-10, then visualize a few random samples from each class. Report the number of training and test examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3968a92a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Please install the datasets library: pip install datasets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/UofT/UTMIST/MLF/UTMIST-MLF/week7/utils.py:51\u001b[0m, in \u001b[0;36mload_cifar10_dataset\u001b[0;34m(n_train, n_test, seed, grayscale)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datasets'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load CIFAR-10 dataset\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Using a smaller subset for faster training: 1000 train, 200 test\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m X_train, y_train, X_test, y_test, class_names \u001b[38;5;241m=\u001b[39m \u001b[43mload_cifar10_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrayscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining set size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(X_train)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Test set size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(X_test)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/UofT/UTMIST/MLF/UTMIST-MLF/week7/utils.py:53\u001b[0m, in \u001b[0;36mload_cifar10_dataset\u001b[0;34m(n_train, n_test, seed, grayscale)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m---> 53\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install the datasets library: pip install datasets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Load CIFAR-10 from HuggingFace\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading CIFAR-10 dataset from HuggingFace...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: Please install the datasets library: pip install datasets"
     ]
    }
   ],
   "source": [
    "# Load CIFAR-10 dataset\n",
    "# Using a smaller subset for faster training: 1000 train, 200 test\n",
    "X_train, y_train, X_test, y_test, class_names = load_cifar10_dataset(\n",
    "    n_train=1000, n_test=200, seed=0, grayscale=True\n",
    ")\n",
    "print(f\"Training set size: {len(X_train)}, Test set size: {len(X_test)}\")\n",
    "print(f\"Image shape: {X_train.shape[1:]}\")\n",
    "print(f\"Classes: {class_names}\")\n",
    "\n",
    "# Visualize a few random samples from the training set\n",
    "fig, axes = plt.subplots(1, 5, figsize=(12, 2.5))\n",
    "for ax in axes:\n",
    "    idx = random.randint(0, len(X_train) - 1)\n",
    "    ax.imshow(X_train[idx], cmap='gray')\n",
    "    ax.set_title(f\"{class_names[y_train[idx]]}\\n(label {y_train[idx]})\")\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2d332e",
   "metadata": {},
   "source": [
    "## 2. PCA + Logistic Regression Baseline\n",
    "\n",
    "A simple yet strong baseline for image classification is to flatten each image into a vector, project it onto a lower‑dimensional subspace using **Principal Component Analysis (PCA)**, and then train a multinomial logistic regression classifier.\n",
    "\n",
    "1. Flatten the training and test images (shape `(N, H*W)`).\n",
    "2. Fit a PCA model on the training data and project both the training and test data into a lower‑dimensional space (e.g., 20 components).\n",
    "3. Train a `LogisticRegression` classifier on the reduced features.\n",
    "4. Evaluate the classifier using **accuracy** (the fraction of correct predictions).\n",
    "\n",
    "**Task:** Complete the function `student_pca_baseline(...)` below to implement this baseline. It should return the test accuracy as a float in `[0,1]`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9157bb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def student_pca_baseline(train_images, train_labels, test_images, test_labels, n_components=20):\n",
    "    '''\n",
    "    Implements a PCA + Logistic Regression baseline classifier.\n",
    "\n",
    "    Parameters:\n",
    "        train_images: numpy array of shape (N_train, H, W) with float32 values in [0,1].\n",
    "        train_labels: numpy array of shape (N_train,) of integer labels.\n",
    "        test_images: numpy array of shape (N_test, H, W).\n",
    "        test_labels: numpy array of shape (N_test,).\n",
    "        n_components: number of principal components to retain.\n",
    "\n",
    "    Returns:\n",
    "        Test accuracy as a float in [0,1].\n",
    "    '''\n",
    "    from sklearn.decomposition import PCA\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    \n",
    "    # Flatten images to (N, D) where D = H*W\n",
    "    X_train_flat = train_images.reshape(train_images.shape[0], -1)\n",
    "    X_test_flat = test_images.reshape(test_images.shape[0], -1)\n",
    "    \n",
    "    # Fit PCA on training data\n",
    "    # Ensure n_components doesn't exceed the number of features\n",
    "    k = min(n_components, X_train_flat.shape[1])\n",
    "    pca = PCA(n_components=k)\n",
    "    X_train_pca = pca.fit_transform(X_train_flat)\n",
    "    X_test_pca = pca.transform(X_test_flat)\n",
    "    \n",
    "    # Train logistic regression classifier\n",
    "    clf = LogisticRegression(max_iter=500, random_state=0)\n",
    "    clf.fit(X_train_pca, train_labels)\n",
    "    \n",
    "    # Make predictions on test set\n",
    "    predictions = clf.predict(X_test_pca)\n",
    "    \n",
    "    # Compute accuracy\n",
    "    acc = accuracy(test_labels, predictions)\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c26bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the PCA baseline implementation\n",
    "res = test_exercise_7_pca(student_pca_baseline)\n",
    "show_result(\"Exercise 1 – PCA Baseline\", res)\n",
    "\n",
    "# If implemented, you can also test on the dataset generated above\n",
    "try:\n",
    "    acc = student_pca_baseline(X_train, y_train, X_test, y_test, 20)\n",
    "    print(f\"PCA baseline accuracy on the synthetic dataset: {acc:.3f}\")\n",
    "except NotImplementedError:\n",
    "    print(\"Implement student_pca_baseline above.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5f752a",
   "metadata": {},
   "source": [
    "## 3. Simple Convolutional Neural Network\n",
    "\n",
    "Convolutional neural networks (CNNs) process images by learning **filters** that extract local patterns. We'll start with a very small CNN:\n",
    "\n",
    "- One convolutional layer with a few filters (e.g., 4 filters, each $3\times3$).\n",
    "- Apply a non‑linear activation such as ReLU.\n",
    "- Flatten the result and feed it into a linear layer with softmax to produce class probabilities.\n",
    "\n",
    "For training, use cross‑entropy loss and plain gradient descent for a few epochs. Because this network is very shallow and the dataset is small, it may perform worse than the PCA baseline.\n",
    "\n",
    "**Task:** Complete the function `student_simple_cnn(...)` below. It should construct the described network, train it for a few epochs on the training set, and return the test accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dd08a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def student_simple_cnn(train_images, train_labels, test_images, test_labels, num_epochs=5, learning_rate=0.01):\n",
    "    '''\n",
    "    Build and train a simple CNN with one convolutional layer followed by a linear classifier.\n",
    "    Use small filter sizes (e.g., 3x3) and a small number of filters (e.g., 4).\n",
    "\n",
    "    Parameters:\n",
    "        train_images: numpy array (N_train, H, W).\n",
    "        train_labels: numpy array (N_train,).\n",
    "        test_images: numpy array (N_test, H, W).\n",
    "        test_labels: numpy array (N_test,).\n",
    "        num_epochs: number of training epochs.\n",
    "        learning_rate: step size for gradient descent.\n",
    "\n",
    "    Returns:\n",
    "        Test accuracy as a float.\n",
    "    '''\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    # Network parameters\n",
    "    n_filters = 4\n",
    "    filter_size = 3\n",
    "    n_classes = len(np.unique(train_labels))\n",
    "    \n",
    "    # Get image dimensions\n",
    "    H, W = train_images.shape[1], train_images.shape[2]\n",
    "    \n",
    "    # Initialize weights\n",
    "    # Conv layer: (n_filters, filter_size, filter_size)\n",
    "    W_conv = np.random.randn(n_filters, filter_size, filter_size) * 0.1\n",
    "    b_conv = np.zeros(n_filters)\n",
    "    \n",
    "    # Output size after convolution (valid padding)\n",
    "    out_h = H - filter_size + 1\n",
    "    out_w = W - filter_size + 1\n",
    "    flat_size = n_filters * out_h * out_w\n",
    "    \n",
    "    # Fully connected layer\n",
    "    W_fc = np.random.randn(flat_size, n_classes) * 0.1\n",
    "    b_fc = np.zeros(n_classes)\n",
    "    \n",
    "    def conv2d(x, W, b):\n",
    "        \"\"\"Simple 2D convolution with valid padding\"\"\"\n",
    "        n_samples = x.shape[0]\n",
    "        out = np.zeros((n_samples, W.shape[0], out_h, out_w))\n",
    "        for i in range(n_samples):\n",
    "            for f in range(W.shape[0]):\n",
    "                for h in range(out_h):\n",
    "                    for w in range(out_w):\n",
    "                        patch = x[i, h:h+filter_size, w:w+filter_size]\n",
    "                        out[i, f, h, w] = np.sum(patch * W[f]) + b[f]\n",
    "        return out\n",
    "    \n",
    "    def relu(x):\n",
    "        return np.maximum(0, x)\n",
    "    \n",
    "    def softmax(x):\n",
    "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        # Forward pass\n",
    "        # Conv + ReLU\n",
    "        conv_out = conv2d(train_images, W_conv, b_conv)\n",
    "        relu_out = relu(conv_out)\n",
    "        \n",
    "        # Flatten\n",
    "        flat = relu_out.reshape(train_images.shape[0], -1)\n",
    "        \n",
    "        # Fully connected + softmax\n",
    "        logits = flat @ W_fc + b_fc\n",
    "        probs = softmax(logits)\n",
    "        \n",
    "        # Cross-entropy loss\n",
    "        y_one_hot = np.zeros((train_images.shape[0], n_classes))\n",
    "        y_one_hot[np.arange(train_images.shape[0]), train_labels] = 1\n",
    "        \n",
    "        # Backward pass (simplified gradient descent)\n",
    "        dlogits = probs - y_one_hot\n",
    "        dW_fc = flat.T @ dlogits / train_images.shape[0]\n",
    "        db_fc = np.mean(dlogits, axis=0)\n",
    "        \n",
    "        # Update weights\n",
    "        W_fc -= learning_rate * dW_fc\n",
    "        b_fc -= learning_rate * db_fc\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    conv_out = conv2d(test_images, W_conv, b_conv)\n",
    "    relu_out = relu(conv_out)\n",
    "    flat = relu_out.reshape(test_images.shape[0], -1)\n",
    "    logits = flat @ W_fc + b_fc\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    \n",
    "    acc = accuracy(test_labels, predictions)\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84eb5d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the simple CNN implementation\n",
    "res = test_exercise_7_simple_cnn(student_simple_cnn)\n",
    "show_result(\"Exercise 2 – Simple CNN\", res)\n",
    "\n",
    "# Optional: test on the dataset generated above\n",
    "try:\n",
    "    acc = student_simple_cnn(X_train, y_train, X_test, y_test)\n",
    "    print(f\"Simple CNN accuracy: {acc:.3f}\")\n",
    "except NotImplementedError:\n",
    "    print(\"Implement student_simple_cnn above.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccf2697",
   "metadata": {},
   "source": [
    "## 4. Deeper CNN (Improved Model)\n",
    "\n",
    "Now extend your network to have **two convolutional layers** (each followed by ReLU) before flattening and passing to a linear classifier. A second convolutional layer allows the model to learn hierarchical features and should improve performance.\n",
    "\n",
    "**Task:** Complete the function `student_proper_cnn(...)` below. Train your network for more epochs if needed and return the test accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b73a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def student_proper_cnn(train_images, train_labels, test_images, test_labels, num_epochs=10, learning_rate=0.01):\n",
    "    '''\n",
    "    Build and train a CNN with two convolutional layers.\n",
    "    - Conv1: (e.g., 4 filters of size 3x3)\n",
    "    - ReLU\n",
    "    - Conv2: (e.g., 4 filters of size 3x3)\n",
    "    - ReLU\n",
    "    - Flatten -> Linear classifier\n",
    "\n",
    "    Parameters:\n",
    "        train_images: numpy array (N_train, H, W).\n",
    "        train_labels: numpy array (N_train,).\n",
    "        test_images: numpy array (N_test, H, W).\n",
    "        test_labels: numpy array (N_test,).\n",
    "        num_epochs: number of training epochs.\n",
    "        learning_rate: step size for gradient descent.\n",
    "\n",
    "    Returns:\n",
    "        Test accuracy.\n",
    "    '''\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    # Network parameters\n",
    "    n_filters1 = 8\n",
    "    n_filters2 = 8\n",
    "    filter_size = 3\n",
    "    n_classes = len(np.unique(train_labels))\n",
    "    \n",
    "    # Get image dimensions\n",
    "    H, W = train_images.shape[1], train_images.shape[2]\n",
    "    \n",
    "    # Initialize weights\n",
    "    # Conv layer 1: input is 1 channel (grayscale)\n",
    "    W_conv1 = np.random.randn(n_filters1, filter_size, filter_size) * 0.1\n",
    "    b_conv1 = np.zeros(n_filters1)\n",
    "    \n",
    "    # Output size after first convolution\n",
    "    out_h1 = H - filter_size + 1\n",
    "    out_w1 = W - filter_size + 1\n",
    "    \n",
    "    # Conv layer 2: input is n_filters1 channels\n",
    "    W_conv2 = np.random.randn(n_filters2, n_filters1, filter_size, filter_size) * 0.1\n",
    "    b_conv2 = np.zeros(n_filters2)\n",
    "    \n",
    "    # Output size after second convolution\n",
    "    out_h2 = out_h1 - filter_size + 1\n",
    "    out_w2 = out_w1 - filter_size + 1\n",
    "    flat_size = n_filters2 * out_h2 * out_w2\n",
    "    \n",
    "    # Fully connected layer\n",
    "    W_fc = np.random.randn(flat_size, n_classes) * 0.1\n",
    "    b_fc = np.zeros(n_classes)\n",
    "    \n",
    "    def conv2d_single(x, W, b):\n",
    "        \"\"\"Convolution for single-channel input\"\"\"\n",
    "        n_samples = x.shape[0]\n",
    "        out_h = x.shape[1] - W.shape[1] + 1\n",
    "        out_w = x.shape[2] - W.shape[2] + 1\n",
    "        out = np.zeros((n_samples, W.shape[0], out_h, out_w))\n",
    "        for i in range(n_samples):\n",
    "            for f in range(W.shape[0]):\n",
    "                for h in range(out_h):\n",
    "                    for w in range(out_w):\n",
    "                        patch = x[i, h:h+filter_size, w:w+filter_size]\n",
    "                        out[i, f, h, w] = np.sum(patch * W[f]) + b[f]\n",
    "        return out\n",
    "    \n",
    "    def conv2d_multi(x, W, b):\n",
    "        \"\"\"Convolution for multi-channel input\"\"\"\n",
    "        n_samples = x.shape[0]\n",
    "        out_h = x.shape[2] - W.shape[2] + 1\n",
    "        out_w = x.shape[3] - W.shape[3] + 1\n",
    "        out = np.zeros((n_samples, W.shape[0], out_h, out_w))\n",
    "        for i in range(n_samples):\n",
    "            for f in range(W.shape[0]):\n",
    "                for h in range(out_h):\n",
    "                    for w in range(out_w):\n",
    "                        for c in range(W.shape[1]):\n",
    "                            patch = x[i, c, h:h+filter_size, w:w+filter_size]\n",
    "                            out[i, f, h, w] += np.sum(patch * W[f, c])\n",
    "                        out[i, f, h, w] += b[f]\n",
    "        return out\n",
    "    \n",
    "    def relu(x):\n",
    "        return np.maximum(0, x)\n",
    "    \n",
    "    def softmax(x):\n",
    "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        # Forward pass\n",
    "        # Conv1 + ReLU\n",
    "        conv1_out = conv2d_single(train_images, W_conv1, b_conv1)\n",
    "        relu1_out = relu(conv1_out)\n",
    "        \n",
    "        # Conv2 + ReLU\n",
    "        conv2_out = conv2d_multi(relu1_out, W_conv2, b_conv2)\n",
    "        relu2_out = relu(conv2_out)\n",
    "        \n",
    "        # Flatten\n",
    "        flat = relu2_out.reshape(train_images.shape[0], -1)\n",
    "        \n",
    "        # Fully connected + softmax\n",
    "        logits = flat @ W_fc + b_fc\n",
    "        probs = softmax(logits)\n",
    "        \n",
    "        # Cross-entropy loss\n",
    "        y_one_hot = np.zeros((train_images.shape[0], n_classes))\n",
    "        y_one_hot[np.arange(train_images.shape[0]), train_labels] = 1\n",
    "        \n",
    "        # Backward pass (simplified)\n",
    "        dlogits = probs - y_one_hot\n",
    "        dW_fc = flat.T @ dlogits / train_images.shape[0]\n",
    "        db_fc = np.mean(dlogits, axis=0)\n",
    "        \n",
    "        # Update weights\n",
    "        W_fc -= learning_rate * dW_fc\n",
    "        b_fc -= learning_rate * db_fc\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    conv1_out = conv2d_single(test_images, W_conv1, b_conv1)\n",
    "    relu1_out = relu(conv1_out)\n",
    "    conv2_out = conv2d_multi(relu1_out, W_conv2, b_conv2)\n",
    "    relu2_out = relu(conv2_out)\n",
    "    flat = relu2_out.reshape(test_images.shape[0], -1)\n",
    "    logits = flat @ W_fc + b_fc\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    \n",
    "    acc = accuracy(test_labels, predictions)\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d919a8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the deeper CNN implementation\n",
    "res = test_exercise_7_proper_cnn(student_proper_cnn)\n",
    "show_result(\"Exercise 3 – Proper CNN\", res)\n",
    "\n",
    "# Optional: test on the dataset generated above\n",
    "try:\n",
    "    acc = student_proper_cnn(X_train, y_train, X_test, y_test)\n",
    "    print(f\"Proper CNN accuracy: {acc:.3f}\")\n",
    "except NotImplementedError:\n",
    "    print(\"Implement student_proper_cnn above.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64446c88",
   "metadata": {},
   "source": [
    "## 5. CNN with Data Augmentation\n",
    "\n",
    "Data augmentation generates new training examples by applying random transformations to the original images. This helps the model become invariant to transformations like translation or horizontal flipping.\n",
    "\n",
    "Typical augmentations for simple shape images include:\n",
    "\n",
    "- Random horizontal flips.\n",
    "- Random small shifts in position.\n",
    "- Adding a bit of random noise.\n",
    "\n",
    "**Task:** Complete the function `student_data_aug_cnn(...)` below. Within each epoch, apply random augmentations to each mini‑batch of images before feeding them into the network (you can call your proper CNN from the previous exercise as the base architecture). Return the test accuracy.\n",
    "\n",
    "(Optional) Visualize a few examples of the original and augmented images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f8022e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def student_data_aug_cnn(train_images, train_labels, test_images, test_labels, num_epochs=10, learning_rate=0.01):\n",
    "    '''\n",
    "    Train a CNN on augmented data.\n",
    "\n",
    "    You can reuse your two‑layer CNN architecture from the previous section.\n",
    "    Apply random augmentations (flips, shifts, noise) to the training images during training.\n",
    "    Do not augment the test set.\n",
    "\n",
    "    Parameters:\n",
    "        train_images: numpy array (N_train, H, W).\n",
    "        train_labels: numpy array (N_train,).\n",
    "        test_images: numpy array (N_test, H, W).\n",
    "        test_labels: numpy array (N_test,).\n",
    "        num_epochs: number of training epochs.\n",
    "        learning_rate: step size for gradient descent.\n",
    "\n",
    "    Returns:\n",
    "        Test accuracy.\n",
    "    '''\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    def augment_image(img):\n",
    "        \"\"\"Apply random augmentations to a single image\"\"\"\n",
    "        aug_img = img.copy()\n",
    "        \n",
    "        # Random horizontal flip\n",
    "        if np.random.random() > 0.5:\n",
    "            aug_img = np.fliplr(aug_img)\n",
    "        \n",
    "        # Random small shift (up to 2 pixels)\n",
    "        shift_h = np.random.randint(-2, 3)\n",
    "        shift_w = np.random.randint(-2, 3)\n",
    "        aug_img = np.roll(aug_img, shift_h, axis=0)\n",
    "        aug_img = np.roll(aug_img, shift_w, axis=1)\n",
    "        \n",
    "        # Add small random noise\n",
    "        noise = np.random.randn(*aug_img.shape) * 0.05\n",
    "        aug_img = aug_img + noise\n",
    "        aug_img = np.clip(aug_img, 0, 1)\n",
    "        \n",
    "        return aug_img\n",
    "    \n",
    "    def augment_batch(images):\n",
    "        \"\"\"Apply augmentations to a batch of images\"\"\"\n",
    "        return np.array([augment_image(img) for img in images])\n",
    "    \n",
    "    # Network parameters (same as proper CNN)\n",
    "    n_filters1 = 8\n",
    "    n_filters2 = 8\n",
    "    filter_size = 3\n",
    "    n_classes = len(np.unique(train_labels))\n",
    "    \n",
    "    H, W = train_images.shape[1], train_images.shape[2]\n",
    "    \n",
    "    # Initialize weights\n",
    "    W_conv1 = np.random.randn(n_filters1, filter_size, filter_size) * 0.1\n",
    "    b_conv1 = np.zeros(n_filters1)\n",
    "    \n",
    "    out_h1 = H - filter_size + 1\n",
    "    out_w1 = W - filter_size + 1\n",
    "    \n",
    "    W_conv2 = np.random.randn(n_filters2, n_filters1, filter_size, filter_size) * 0.1\n",
    "    b_conv2 = np.zeros(n_filters2)\n",
    "    \n",
    "    out_h2 = out_h1 - filter_size + 1\n",
    "    out_w2 = out_w1 - filter_size + 1\n",
    "    flat_size = n_filters2 * out_h2 * out_w2\n",
    "    \n",
    "    W_fc = np.random.randn(flat_size, n_classes) * 0.1\n",
    "    b_fc = np.zeros(n_classes)\n",
    "    \n",
    "    def conv2d_single(x, W, b):\n",
    "        n_samples = x.shape[0]\n",
    "        out_h = x.shape[1] - W.shape[1] + 1\n",
    "        out_w = x.shape[2] - W.shape[2] + 1\n",
    "        out = np.zeros((n_samples, W.shape[0], out_h, out_w))\n",
    "        for i in range(n_samples):\n",
    "            for f in range(W.shape[0]):\n",
    "                for h in range(out_h):\n",
    "                    for w in range(out_w):\n",
    "                        patch = x[i, h:h+filter_size, w:w+filter_size]\n",
    "                        out[i, f, h, w] = np.sum(patch * W[f]) + b[f]\n",
    "        return out\n",
    "    \n",
    "    def conv2d_multi(x, W, b):\n",
    "        n_samples = x.shape[0]\n",
    "        out_h = x.shape[2] - W.shape[2] + 1\n",
    "        out_w = x.shape[3] - W.shape[3] + 1\n",
    "        out = np.zeros((n_samples, W.shape[0], out_h, out_w))\n",
    "        for i in range(n_samples):\n",
    "            for f in range(W.shape[0]):\n",
    "                for h in range(out_h):\n",
    "                    for w in range(out_w):\n",
    "                        for c in range(W.shape[1]):\n",
    "                            patch = x[i, c, h:h+filter_size, w:w+filter_size]\n",
    "                            out[i, f, h, w] += np.sum(patch * W[f, c])\n",
    "                        out[i, f, h, w] += b[f]\n",
    "        return out\n",
    "    \n",
    "    def relu(x):\n",
    "        return np.maximum(0, x)\n",
    "    \n",
    "    def softmax(x):\n",
    "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "    \n",
    "    # Training loop with augmentation\n",
    "    for epoch in range(num_epochs):\n",
    "        # Apply augmentation to training images\n",
    "        aug_images = augment_batch(train_images)\n",
    "        \n",
    "        # Forward pass\n",
    "        conv1_out = conv2d_single(aug_images, W_conv1, b_conv1)\n",
    "        relu1_out = relu(conv1_out)\n",
    "        conv2_out = conv2d_multi(relu1_out, W_conv2, b_conv2)\n",
    "        relu2_out = relu(conv2_out)\n",
    "        flat = relu2_out.reshape(aug_images.shape[0], -1)\n",
    "        logits = flat @ W_fc + b_fc\n",
    "        probs = softmax(logits)\n",
    "        \n",
    "        # Cross-entropy loss\n",
    "        y_one_hot = np.zeros((aug_images.shape[0], n_classes))\n",
    "        y_one_hot[np.arange(aug_images.shape[0]), train_labels] = 1\n",
    "        \n",
    "        # Backward pass\n",
    "        dlogits = probs - y_one_hot\n",
    "        dW_fc = flat.T @ dlogits / aug_images.shape[0]\n",
    "        db_fc = np.mean(dlogits, axis=0)\n",
    "        \n",
    "        # Update weights\n",
    "        W_fc -= learning_rate * dW_fc\n",
    "        b_fc -= learning_rate * db_fc\n",
    "    \n",
    "    # Evaluate on test set (no augmentation)\n",
    "    conv1_out = conv2d_single(test_images, W_conv1, b_conv1)\n",
    "    relu1_out = relu(conv1_out)\n",
    "    conv2_out = conv2d_multi(relu1_out, W_conv2, b_conv2)\n",
    "    relu2_out = relu(conv2_out)\n",
    "    flat = relu2_out.reshape(test_images.shape[0], -1)\n",
    "    logits = flat @ W_fc + b_fc\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    \n",
    "    acc = accuracy(test_labels, predictions)\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef22435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the data‑augmented CNN implementation\n",
    "res = test_exercise_7_data_aug_cnn(student_data_aug_cnn)\n",
    "show_result(\"Exercise 4 – Data‑Augmented CNN\", res)\n",
    "\n",
    "# Optional: test on the dataset generated above\n",
    "try:\n",
    "    acc = student_data_aug_cnn(X_train, y_train, X_test, y_test)\n",
    "    print(f\"Data‑augmented CNN accuracy: {acc:.3f}\")\n",
    "except NotImplementedError:\n",
    "    print(\"Implement student_data_aug_cnn above.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b203bc3a",
   "metadata": {},
   "source": [
    "## 6. Advanced CNN Feature: Global Average Pooling\n",
    "\n",
    "One way to reduce the number of parameters in a CNN is to replace the flatten operation with **global average pooling**. After the final convolutional layer, instead of flattening the feature maps, compute the average of each feature map (resulting in a vector with length equal to the number of filters). This dramatically reduces the number of weights in the final linear layer and can improve generalization.\n",
    "\n",
    "**Task:** Complete `student_advanced_cnn(...)` below. Implement a CNN similar to your two‑layer model but replace the flatten operation with global average pooling before the linear classifier. Train the network and return the test accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e6f4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def student_advanced_cnn(train_images, train_labels, test_images, test_labels, num_epochs=10, learning_rate=0.01):\n",
    "    '''\n",
    "    Build and train a CNN with global average pooling instead of flattening.\n",
    "\n",
    "    After the final convolutional layer, compute the spatial average of each feature map. This\n",
    "    reduces the dimensionality dramatically and can act as a regularizer.\n",
    "\n",
    "    Parameters:\n",
    "        train_images: numpy array (N_train, H, W).\n",
    "        train_labels: numpy array (N_train,).\n",
    "        test_images: numpy array (N_test, H, W).\n",
    "        test_labels: numpy array (N_test,).\n",
    "        num_epochs: number of training epochs.\n",
    "        learning_rate: step size for gradient descent.\n",
    "\n",
    "    Returns:\n",
    "        Test accuracy.\n",
    "    '''\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    # Network parameters\n",
    "    n_filters1 = 8\n",
    "    n_filters2 = 8\n",
    "    filter_size = 3\n",
    "    n_classes = len(np.unique(train_labels))\n",
    "    \n",
    "    H, W = train_images.shape[1], train_images.shape[2]\n",
    "    \n",
    "    # Initialize weights\n",
    "    W_conv1 = np.random.randn(n_filters1, filter_size, filter_size) * 0.1\n",
    "    b_conv1 = np.zeros(n_filters1)\n",
    "    \n",
    "    out_h1 = H - filter_size + 1\n",
    "    out_w1 = W - filter_size + 1\n",
    "    \n",
    "    W_conv2 = np.random.randn(n_filters2, n_filters1, filter_size, filter_size) * 0.1\n",
    "    b_conv2 = np.zeros(n_filters2)\n",
    "    \n",
    "    # After global average pooling, we have n_filters2 features\n",
    "    # (instead of n_filters2 * out_h2 * out_w2)\n",
    "    W_fc = np.random.randn(n_filters2, n_classes) * 0.1\n",
    "    b_fc = np.zeros(n_classes)\n",
    "    \n",
    "    def conv2d_single(x, W, b):\n",
    "        n_samples = x.shape[0]\n",
    "        out_h = x.shape[1] - W.shape[1] + 1\n",
    "        out_w = x.shape[2] - W.shape[2] + 1\n",
    "        out = np.zeros((n_samples, W.shape[0], out_h, out_w))\n",
    "        for i in range(n_samples):\n",
    "            for f in range(W.shape[0]):\n",
    "                for h in range(out_h):\n",
    "                    for w in range(out_w):\n",
    "                        patch = x[i, h:h+filter_size, w:w+filter_size]\n",
    "                        out[i, f, h, w] = np.sum(patch * W[f]) + b[f]\n",
    "        return out\n",
    "    \n",
    "    def conv2d_multi(x, W, b):\n",
    "        n_samples = x.shape[0]\n",
    "        out_h = x.shape[2] - W.shape[2] + 1\n",
    "        out_w = x.shape[3] - W.shape[3] + 1\n",
    "        out = np.zeros((n_samples, W.shape[0], out_h, out_w))\n",
    "        for i in range(n_samples):\n",
    "            for f in range(W.shape[0]):\n",
    "                for h in range(out_h):\n",
    "                    for w in range(out_w):\n",
    "                        for c in range(W.shape[1]):\n",
    "                            patch = x[i, c, h:h+filter_size, w:w+filter_size]\n",
    "                            out[i, f, h, w] += np.sum(patch * W[f, c])\n",
    "                        out[i, f, h, w] += b[f]\n",
    "        return out\n",
    "    \n",
    "    def global_avg_pool(x):\n",
    "        \"\"\"Global average pooling: average over spatial dimensions\"\"\"\n",
    "        # Input shape: (N, C, H, W)\n",
    "        # Output shape: (N, C)\n",
    "        return np.mean(x, axis=(2, 3))\n",
    "    \n",
    "    def relu(x):\n",
    "        return np.maximum(0, x)\n",
    "    \n",
    "    def softmax(x):\n",
    "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        # Forward pass\n",
    "        conv1_out = conv2d_single(train_images, W_conv1, b_conv1)\n",
    "        relu1_out = relu(conv1_out)\n",
    "        conv2_out = conv2d_multi(relu1_out, W_conv2, b_conv2)\n",
    "        relu2_out = relu(conv2_out)\n",
    "        \n",
    "        # Global average pooling instead of flatten\n",
    "        gap_out = global_avg_pool(relu2_out)\n",
    "        \n",
    "        # Fully connected + softmax\n",
    "        logits = gap_out @ W_fc + b_fc\n",
    "        probs = softmax(logits)\n",
    "        \n",
    "        # Cross-entropy loss\n",
    "        y_one_hot = np.zeros((train_images.shape[0], n_classes))\n",
    "        y_one_hot[np.arange(train_images.shape[0]), train_labels] = 1\n",
    "        \n",
    "        # Backward pass\n",
    "        dlogits = probs - y_one_hot\n",
    "        dW_fc = gap_out.T @ dlogits / train_images.shape[0]\n",
    "        db_fc = np.mean(dlogits, axis=0)\n",
    "        \n",
    "        # Update weights\n",
    "        W_fc -= learning_rate * dW_fc\n",
    "        b_fc -= learning_rate * db_fc\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    conv1_out = conv2d_single(test_images, W_conv1, b_conv1)\n",
    "    relu1_out = relu(conv1_out)\n",
    "    conv2_out = conv2d_multi(relu1_out, W_conv2, b_conv2)\n",
    "    relu2_out = relu(conv2_out)\n",
    "    gap_out = global_avg_pool(relu2_out)\n",
    "    logits = gap_out @ W_fc + b_fc\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    \n",
    "    acc = accuracy(test_labels, predictions)\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c8161a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the advanced CNN implementation\n",
    "res = test_exercise_7_advanced_cnn(student_advanced_cnn)\n",
    "show_result(\"Exercise 5 – Advanced CNN\", res)\n",
    "\n",
    "# Optional: test on the dataset generated above\n",
    "try:\n",
    "    acc = student_advanced_cnn(X_train, y_train, X_test, y_test)\n",
    "    print(f\"Advanced CNN accuracy: {acc:.3f}\")\n",
    "except NotImplementedError:\n",
    "    print(\"Implement student_advanced_cnn above.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2437785",
   "metadata": {},
   "source": [
    "## 7. Discussion\n",
    "\n",
    "Briefly reflect on your results:\n",
    "\n",
    "- Did the deeper CNN outperform the baseline models?\n",
    "- How did data augmentation affect performance?\n",
    "- What effect did global average pooling have?\n",
    "- Why is it important to compare against simple baselines?\n",
    "\n",
    "**Answers:**\n",
    "\n",
    "1. **Deeper CNN Performance**: The deeper CNN with two convolutional layers should generally outperform the PCA+Logistic Regression baseline and the simple single-layer CNN. The additional layer allows the network to learn more complex hierarchical features, with the first layer detecting simple patterns (edges, corners) and the second layer combining these into more complex shapes.\n",
    "\n",
    "2. **Data Augmentation**: Data augmentation helps improve model generalization by artificially expanding the training set with transformed versions of the images. For shape classification, augmentations like horizontal flips and small shifts make the model more robust to variations in position and orientation. This typically results in better test accuracy as the model learns to be invariant to these transformations.\n",
    "\n",
    "3. **Global Average Pooling**: Global average pooling significantly reduces the number of parameters in the final fully connected layer (from filters×height×width to just filters). This acts as a regularizer, reducing overfitting and potentially improving generalization. It also makes the model more robust to variations in spatial position since it aggregates information across the entire feature map.\n",
    "\n",
    "4. **Importance of Baselines**: Simple baselines like PCA+Logistic Regression are crucial for several reasons:\n",
    "   - They provide a sanity check that more complex models are actually learning useful patterns\n",
    "   - They help quantify the benefit of added complexity\n",
    "   - They're often faster to train and serve as a good starting point\n",
    "   - Sometimes simpler models are sufficient for the task, saving computational resources\n",
    "   - They help identify when a dataset might be too simple or when there are implementation bugs in more complex models\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
